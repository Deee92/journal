{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape (750, 14)\n",
      "Test data shape (200, 13)\n"
     ]
    }
   ],
   "source": [
    "training=pd.read_csv('training_data.csv', sep=',')\n",
    "test=pd.read_csv('songs_to_classify.csv', sep=',')\n",
    "print(\"Training data shape\", training.shape)\n",
    "print(\"Test data shape\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   acousticness  danceability  duration  energy  instrumentalness  key  \\\n",
      "0         0.713         0.514    100125   0.521          0.816000    8   \n",
      "1         0.192         0.714    207019   0.614          0.000000    4   \n",
      "2         0.333         0.630    216200   0.455          0.000004    5   \n",
      "3         0.601         0.810    136413   0.221          0.210000    5   \n",
      "4         0.883         0.465    181440   0.459          0.000173    6   \n",
      "\n",
      "   liveness  loudness  mode  speechiness    tempo  time_signature  valence  \\\n",
      "0    0.1120   -14.835     0       0.0444  119.879               4    0.143   \n",
      "1    0.2630    -6.935     1       0.0319  123.969               4    0.582   \n",
      "2    0.1270    -9.290     1       0.0292  139.931               4    0.199   \n",
      "3    0.1840   -11.005     1       0.0429  109.960               4    0.798   \n",
      "4    0.0692    -8.137     0       0.0351   90.807               4    0.288   \n",
      "\n",
      "   label  \n",
      "0      1  \n",
      "1      1  \n",
      "2      1  \n",
      "3      1  \n",
      "4      1  \n"
     ]
    }
   ],
   "source": [
    "print(training.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess\n",
    "- Scale numerical values\n",
    "- Encode categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape (750, 28)\n",
      "y_train shape (750,)\n",
      "X_test shape (200, 28)\n"
     ]
    }
   ],
   "source": [
    "scaling_cols = ['acousticness', 'danceability', 'duration', 'energy', 'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo', 'valence']\n",
    "categorical_cols = ['key', 'time_signature', 'mode']\n",
    "\n",
    "scaling_transformer = Pipeline(steps=[\n",
    "    ('scaler', MinMaxScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('scale', scaling_transformer, scaling_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)])\n",
    "\n",
    "p = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n",
    "X_train = p.fit_transform(training.drop('label', axis=1))\n",
    "y_train = training['label']\n",
    "print(\"X_train shape\", X_train.shape)\n",
    "print(\"y_train shape\", y_train.shape)\n",
    "\n",
    "X_test = p.fit_transform(test)\n",
    "print(\"X_test shape\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.72       0.68666667 0.77333333 0.74666667 0.66666667]\n",
      "cv_scores mean: 0.7186666666666667\n"
     ]
    }
   ],
   "source": [
    "knnmodel = KNeighborsClassifier(n_neighbors = 5)\n",
    "\n",
    "cv_scores = cross_val_score(knnmodel, X=X_train, y=y_train, cv=5)\n",
    "\n",
    "print(cv_scores)\n",
    "print(\"cv_scores mean: {}\".format(np.mean(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knnmodel.fit(X=X_train,y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 1 0 0 0 1 1 1 1 0 1 1 1 1 1 0 1 1 0 0 1 1 0 0 0 0 0 0 1 0 0 1 1 1\n",
      "  0 0 1 1 0 1 0 1 1 1 0 1 1 0 0 0 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 1 0 0 1 1\n",
      "  0 1 0 0 0 1 1 0 1 1 1 0 0 1 1 0 1 0 1 0 1 0 0 0 1 1 1 1 0 0 1 1 1 0 0 1\n",
      "  1 1 1 0 0 1 1 1 1 1 0 0 0 1 1 0 1 1 0 0 1 0 1 0 1 1 1 1 1 1 1 0 0 0 1 1\n",
      "  1 1 0 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 0 0 1 0 0 1 1 1 1 0\n",
      "  1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "predictions_knn = knnmodel.predict(X=X_test).reshape(-1,1).astype(int).reshape(1,-1)\n",
    "print(predictions_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.78666667 0.78       0.82666667 0.80666667 0.77333333]\n",
      "cv_scores mean: 0.7946666666666667\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=0)\n",
    "cv_scores = cross_val_score(lr, X=X_train, y=y_train, cv=5)\n",
    "print(cv_scores)\n",
    "print(\"cv_scores mean: {}\".format(np.mean(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 1 0 0 1 1 1 0 1 1 0 1 1 0 1 0 1 1 0 0 1 1 0 0 1 1 0 0 1 0 0 1 1 1\n",
      "  1 1 0 1 0 1 0 1 0 1 0 1 1 0 0 0 1 1 0 1 1 0 0 0 1 1 0 0 1 1 1 1 1 0 1 0\n",
      "  1 1 0 1 0 1 1 0 1 1 1 1 0 1 1 1 1 0 1 0 0 0 1 0 1 1 1 1 0 0 1 0 0 1 0 1\n",
      "  1 1 1 0 0 1 1 1 1 0 1 0 0 1 1 0 1 1 1 0 1 0 1 0 1 1 1 1 1 1 0 1 1 0 0 0\n",
      "  1 1 0 0 1 0 1 1 0 0 1 1 1 1 1 0 0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 0 1 1 1 0\n",
      "  0 1 1 1 1 1 1 0 1 0 0 1 1 0 1 0 0 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "lr.fit(X_train, y_train)\n",
    "predictions_lr = lr.predict(X_test).reshape(-1,1).astype(int).reshape(1,-1)\n",
    "print(predictions_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76       0.82       0.83333333 0.82666667 0.78      ]\n",
      "cv_scores mean: 0.804\n"
     ]
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n",
    "cv_scores = cross_val_score(lda, X=X_train, y=y_train, cv=5)\n",
    "print(cv_scores)\n",
    "print(\"cv_scores mean: {}\".format(np.mean(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 1 0 0 1 1 1 0 1 1 0 1 1 0 1 0 1 1 0 0 1 1 0 0 1 0 0 0 1 1 0 1 1 1\n",
      "  1 1 0 1 0 1 0 1 0 1 0 1 1 0 0 1 1 1 1 1 1 0 0 0 1 1 0 0 1 1 1 1 1 0 1 0\n",
      "  1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 0 0 0 1 0 1 1 1 1 0 0 1 1 1 1 0 1\n",
      "  1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 0\n",
      "  1 1 0 0 1 0 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 0\n",
      "  1 1 1 1 1 1 1 0 1 0 0 1 1 0 1 0 0 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "lda.fit(X_train, y_train)\n",
    "predictions_lda = lda.predict(X_test).reshape(-1,1).astype(int).reshape(1,-1)\n",
    "print(predictions_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.65333333 0.77333333 0.46       0.64666667 0.72666667]\n",
      "cv_scores mean: 0.6519999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/user/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/user/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/user/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/user/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "qda = QuadraticDiscriminantAnalysis()\n",
    "cv_scores = cross_val_score(qda, X=X_train, y=y_train, cv=5)\n",
    "print(cv_scores)\n",
    "print(\"cv_scores mean: {}\".format(np.mean(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 1 1 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1 0\n",
      "  1 0 1 0 1 0 0 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 0 1 1 0 1 0 0 0 1 0 1 0\n",
      "  1 1 0 0 0 1 1 0 1 1 1 0 0 1 1 0 1 0 1 0 1 0 1 0 1 1 1 0 0 0 1 0 1 0 0 1\n",
      "  0 1 1 0 0 1 1 0 1 0 1 0 1 1 1 0 0 0 0 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0\n",
      "  1 1 0 0 1 0 1 0 1 0 1 1 1 1 1 0 0 0 0 0 1 0 0 1 1 0 0 1 1 0 0 0 1 1 0 1\n",
      "  1 1 1 1 0 1 0 1 1 0 0 0 1 0 1 0 1 1 1 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "qda.fit(X_train, y_train)\n",
    "predictions_qda = qda.predict(X_test).reshape(-1,1).astype(int).reshape(1,-1)\n",
    "print(predictions_qda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 1 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 1 0 1 1 0 0 1 0 1 0 1 1 0 1 0 1\n",
      "  0 1 0 0 0 1 0 1 0 0 0 1 1 0 0 0 1 1 0 1 1 1 0 0 1 1 1 0 1 1 1 1 0 0 0 1\n",
      "  0 1 1 1 0 1 1 0 1 1 0 0 1 1 1 0 1 0 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0\n",
      "  1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 1 1 0 1 0\n",
      "  1 1 0 0 0 0 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 0 0 0 0 1 0 0\n",
      "  0 0 1 1 1 0 1 0 1 0 0 1 1 0 1 1 0 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "tree_clf = tree.DecisionTreeClassifier()\n",
    "tree_clf.fit(X_train, y_train)\n",
    "predictions_tree = tree_clf.predict(X_test).reshape(-1,1).astype(int).reshape(1,-1)\n",
    "print(predictions_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree.plot_tree(tree_clf) \n",
    "# dot_data = tree.export_graphviz(tree_clf, out_file=None, \n",
    "#                       filled=True, rounded=True,  \n",
    "#                       special_characters=True)  \n",
    "# graph = graphviz.Source(dot_data)\n",
    "# graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
